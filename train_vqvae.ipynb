{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZahraFayyaz/3dshape-vqvae-pyTorch/blob/main/train_vqvae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uqt-IlG47el4"
      },
      "source": [
        "# Import modules"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymNc55c0x_vo",
        "outputId": "b15d8665-f01d-4ca8-cf5c-9dc484402944"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
            "Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjbJ19kth4El",
        "outputId": "93d307e9-fb79-48f4-debf-68b22341b790"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/INI - Generative Episodic Memory\n"
          ]
        }
      ],
      "source": [
        "import sys, os, yaml\n",
        "# connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Enter the foldername where all modules are stored together\n",
        "FOLDERNAME = 'INI - Generative Episodic Memory/'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "# Change the working/current directory\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
        "%cd /content/drive/My\\ Drive/$FOLDERNAME/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "idMQSyEjxh6_"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from data_loader import load_data\n",
        "from vqvae import get_model\n",
        "# import argparse\n",
        "import random\n",
        "# import shutil\n",
        "import cv2\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.optim import Adam\n",
        "from torchvision.utils import make_grid\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mcnDTVS45Ih",
        "outputId": "440316c4-73b7-44b1-8290-cdc33e0c0f3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model_params': {'in_channels': 3, 'convbn_blocks': 4, 'conv_kernel_size': [3, 3, 3, 2], 'conv_kernel_strides': [2, 2, 1, 1], 'convbn_channels': [3, 6, 12, 24, 72], 'conv_activation_fn': 'relu', 'transpose_bn_blocks': 4, 'transposebn_channels': [72, 24, 12, 6, 3], 'transpose_kernel_size': [3, 3, 3, 2], 'transpose_kernel_strides': [2, 2, 1, 1], 'transpose_activation_fn': 'relu', 'latent_dim': 72, 'codebook_size': 10}, 'train_params': {'task_name': 'vqvae_latent_72_codebook_10_nnLayers_4', 'batch_size': 72, 'epochs': 10, 'lr': 0.005, 'crit': 'l2', 'reconstruction_loss_weight': 1, 'codebook_loss_weight': 1, 'commitment_loss_weight': 0.2, 'ckpt_name': 'best_vqvae_latent_72_codebook_10.pth', 'seed': 42, 'save_training_image': True, 'path': '/content/drive/MyDrive/Data/3dshapes.h5', 'output_train_dir': 'output'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished epoch: 1 | Recon Loss : 0.1149 | Codebook Loss : 0.3571 | Commitment Loss : 0.3571\n",
            "Improved Loss to 0.5435 .... Saving Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished epoch: 2 | Recon Loss : 0.0767 | Codebook Loss : 0.3223 | Commitment Loss : 0.3223\n",
            "Improved Loss to 0.4634 .... Saving Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished epoch: 3 | Recon Loss : 0.0710 | Codebook Loss : 0.2797 | Commitment Loss : 0.2797\n",
            "Improved Loss to 0.4066 .... Saving Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished epoch: 4 | Recon Loss : 0.0707 | Codebook Loss : 0.2868 | Commitment Loss : 0.2868\n",
            "No Loss Improvement\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished epoch: 5 | Recon Loss : 0.0683 | Codebook Loss : 0.2816 | Commitment Loss : 0.2816\n",
            "Improved Loss to 0.4062 .... Saving Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished epoch: 6 | Recon Loss : 0.0651 | Codebook Loss : 0.2652 | Commitment Loss : 0.2652\n",
            "Improved Loss to 0.3833 .... Saving Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished epoch: 7 | Recon Loss : 0.0633 | Codebook Loss : 0.2540 | Commitment Loss : 0.2540\n",
            "Improved Loss to 0.3681 .... Saving Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished epoch: 8 | Recon Loss : 0.0623 | Codebook Loss : 0.2582 | Commitment Loss : 0.2582\n",
            "No Loss Improvement\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished epoch: 9 | Recon Loss : 0.0604 | Codebook Loss : 0.2495 | Commitment Loss : 0.2495\n",
            "Improved Loss to 0.3597 .... Saving Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished epoch: 10 | Recon Loss : 0.0599 | Codebook Loss : 0.2480 | Commitment Loss : 0.2480\n",
            "Improved Loss to 0.3575 .... Saving Model\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def train_for_one_epoch(epoch_idx, model, data_loader, optimizer, crtierion, config, save_indices=False):\n",
        "    r\"\"\"\n",
        "    Method to run the training for one epoch.\n",
        "    :param epoch_idx: iteration number of current epoch\n",
        "    :param model: VQVAE model\n",
        "    :param data_loader: Data loder for mnist\n",
        "    :param optimizer: optimzier to be used taken from config\n",
        "    :param crtierion: For computing the loss\n",
        "    :param config: configuration for the current run\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    recon_losses = []\n",
        "    codebook_losses = []\n",
        "    commitment_losses = []\n",
        "    losses = []\n",
        "    # List to collect indices of all images\n",
        "    all_indices = []\n",
        "\n",
        "    count = 0\n",
        "    for im, label in tqdm(data_loader, desc='Training', leave=False): # Ignore the label in DataLoader\n",
        "        im = im.float().to(device)\n",
        "        optimizer.zero_grad()\n",
        "        model_output = model(im)\n",
        "        output = model_output['generated_image']\n",
        "        quantize_losses = model_output['quantized_losses']\n",
        "        z_q = model_output['quantized_output']\n",
        "        indices = model_output['quantized_indices']\n",
        "\n",
        "        # if config['train_params']['save_training_image']:\n",
        "        #     cv2.imwrite('input.jpeg', (255 * (im.detach() + 1) / 2).cpu().permute(0, 1, 2, 3).numpy().astype(np.uint8)) #(255 * (im.detach() + 1) / 2).cpu().permute((0, 2, 3, 1)).numpy()[0]\n",
        "        #     cv2.imwrite('output.jpeg', (255 * (output.detach() + 1) / 2).cpu().permute(0, 1, 2, 3).numpy().astype(np.uint8)) #(255 * (output.detach() + 1) / 2).cpu().permute((0, 2, 3, 1)).numpy()[0]\n",
        "\n",
        "        recon_loss = crtierion(output, im)\n",
        "        loss = (config['train_params']['reconstruction_loss_weight']*recon_loss +\n",
        "                config['train_params']['codebook_loss_weight']*quantize_losses['codebook_loss'] +\n",
        "                config['train_params']['commitment_loss_weight']*quantize_losses['commitment_loss'])\n",
        "        recon_losses.append(recon_loss.item())\n",
        "        codebook_losses.append(config['train_params']['codebook_loss_weight']*quantize_losses['codebook_loss'].item())\n",
        "        commitment_losses.append(quantize_losses['commitment_loss'].item())\n",
        "        losses.append(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Collect indices for all images\n",
        "        all_indices.append(indices.cpu())\n",
        "\n",
        "    # Save indices if save_indices is True\n",
        "    if save_indices:\n",
        "        all_indices_tensor = torch.cat(all_indices, dim=0)\n",
        "\n",
        "    print('Finished epoch: {} | Recon Loss : {:.4f} | Codebook Loss : {:.4f} | Commitment Loss : {:.4f}'.\n",
        "          format(epoch_idx + 1,\n",
        "                 np.mean(recon_losses),\n",
        "                 np.mean(codebook_losses),\n",
        "                 np.mean(commitment_losses)))\n",
        "    return np.mean(losses)#, all_indices_tensor\n",
        "\n",
        "\n",
        "def train(config_path, sample=None):\n",
        "    ######## Read the config file #######\n",
        "    with open(config_path, 'r') as file:\n",
        "        try:\n",
        "            config = yaml.safe_load(file)\n",
        "        except yaml.YAMLError as exc:\n",
        "            print(exc)\n",
        "    # print(config)\n",
        "    #######################################\n",
        "\n",
        "    ######## Set the desired seed value #######\n",
        "    seed = config['train_params']['seed']\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    if device == 'cuda':\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        # print(args.seed)\n",
        "    #######################################\n",
        "\n",
        "    # Create the model and dataset\n",
        "    model = get_model(config).to(device)\n",
        "    data_loader = load_data(config['train_params']['path'],sample_data=sample)\n",
        "    num_epochs = config['train_params']['epochs']\n",
        "    optimizer = Adam(model.parameters(), lr=config['train_params']['lr'])\n",
        "    # scheduler = ReduceLROnPlateau(optimizer, factor=0.5, patience=1, verbose=True)\n",
        "    criterion = {\n",
        "        'l1': torch.nn.L1Loss(),\n",
        "        'l2': torch.nn.MSELoss()\n",
        "    }.get(config['train_params']['crit'])\n",
        "\n",
        "    # Create output directories\n",
        "    if not os.path.exists(config['train_params']['task_name']):\n",
        "        os.mkdir(config['train_params']['task_name'])\n",
        "    if not os.path.exists(os.path.join(config['train_params']['task_name'],\n",
        "                                       config['train_params']['output_train_dir'])):\n",
        "        os.mkdir(os.path.join(config['train_params']['task_name'],\n",
        "                              config['train_params']['output_train_dir']))\n",
        "\n",
        "    # Load checkpoint if found\n",
        "    # if os.path.exists(os.path.join(config['train_params']['task_name'],\n",
        "        #                                                 config['train_params']['ckpt_name'])):\n",
        "        # print('Loading checkpoint')\n",
        "        # model.load_state_dict(torch.load(os.path.join(config['train_params']['task_name'],\n",
        "        #                                               config['train_params']['ckpt_name']), map_location=device))\n",
        "    best_loss = np.inf\n",
        "\n",
        "    for epoch_idx in range(num_epochs):\n",
        "        mean_loss = train_for_one_epoch(epoch_idx, model, data_loader, optimizer, criterion, config)\n",
        "        # scheduler.step(mean_loss)\n",
        "        # Simply update checkpoint if found better version\n",
        "        if mean_loss < best_loss:\n",
        "            print('Improved Loss to {:.4f} .... Saving Model'.format(mean_loss))\n",
        "            torch.save(model.state_dict(), os.path.join(config['train_params']['task_name'],\n",
        "                                                        config['train_params']['ckpt_name']))\n",
        "            best_loss = mean_loss\n",
        "        else:\n",
        "            print('No Loss Improvement')\n",
        "\n",
        "    #torch.save(indices_tensor, 'quantized_indices.pt')\n",
        "    embedding_weights = model.quantizer.embedding.weight.detach().cpu()\n",
        "    #torch.save(embedding_weights, 'learned_codebook.pt')\n",
        "    return model\n",
        "# def save_embedding_weights(model, file_path):\n",
        "#     # Save the learned embedding weights\n",
        "#     embedding_weights = model.quantizer.embedding.weight.detach().cpu()\n",
        "#     torch.save(embedding_weights, file_path)\n",
        "\n",
        "# def load_embedding_weights(file_path):\n",
        "#     # Load the saved embedding weights\n",
        "#     return torch.load(file_path)\n",
        "\n",
        "# def get_quantized_output_from_indices(model, indices):\n",
        "#     # Get quantized output from indices\n",
        "#     quantized_output = model.quantizer.quantize_indices(indices)\n",
        "#     return quantized_output\n",
        "\n",
        "\n",
        "model= train(config_path='hyperparameters.yaml')\n",
        "# kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "# for fold, (train_idx, val_idx) in enumerate(kf.split(data)):\n",
        "#     print(f\"Fold {fold + 1}\")\n",
        "\n",
        "#     # Create data samplers\n",
        "#     train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "#     val_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
        "\n",
        "#     # Create data loaders\n",
        "#     train_loader = load_data(config['train_params']['path'],sample_data=train_sampler)\n",
        "#     val_loader = load_data(config['train_params']['path'],sample_data=val_sampler)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sSxObCYC9Qyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.parameters()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFxvzPM19BHj",
        "outputId": "6d1ce7fc-c159-4276-b471-e2ea142534bd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7bf4cb8fd3f0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# upload external file before import\n",
        "from google.colab import files\n"
      ],
      "metadata": {
        "id": "kcI67TlL-TKf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '3d400.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "iexrOjDz-CTH",
        "outputId": "a27b506f-61f2-4447-fe59-00d0183c0a0d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dcd38eb6-43a6-4e4e-9451-8ff0fb48b6d7\", \"3d400.pth\", 139658)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load('3d400.pth')\n",
        "print(state_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKDZNMTr-wGG",
        "outputId": "c485b2d4-2394-4a0e-c393-ff509371717b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['encoder.encoder_layers.0.0.weight', 'encoder.encoder_layers.0.0.bias', 'encoder.encoder_layers.0.1.weight', 'encoder.encoder_layers.0.1.bias', 'encoder.encoder_layers.0.1.running_mean', 'encoder.encoder_layers.0.1.running_var', 'encoder.encoder_layers.0.1.num_batches_tracked', 'encoder.encoder_layers.1.0.weight', 'encoder.encoder_layers.1.0.bias', 'encoder.encoder_layers.1.1.weight', 'encoder.encoder_layers.1.1.bias', 'encoder.encoder_layers.1.1.running_mean', 'encoder.encoder_layers.1.1.running_var', 'encoder.encoder_layers.1.1.num_batches_tracked', 'encoder.encoder_layers.2.0.weight', 'encoder.encoder_layers.2.0.bias', 'encoder.encoder_layers.2.1.weight', 'encoder.encoder_layers.2.1.bias', 'encoder.encoder_layers.2.1.running_mean', 'encoder.encoder_layers.2.1.running_var', 'encoder.encoder_layers.2.1.num_batches_tracked', 'encoder.encoder_layers.3.0.weight', 'encoder.encoder_layers.3.0.bias', 'encoder.encoder_layers.3.1.weight', 'encoder.encoder_layers.3.1.bias', 'encoder.encoder_layers.3.1.running_mean', 'encoder.encoder_layers.3.1.running_var', 'encoder.encoder_layers.3.1.num_batches_tracked', 'quantizer.embedding.weight', 'decoder.decoder_layers.0.0.weight', 'decoder.decoder_layers.0.0.bias', 'decoder.decoder_layers.0.1.weight', 'decoder.decoder_layers.0.1.bias', 'decoder.decoder_layers.0.1.running_mean', 'decoder.decoder_layers.0.1.running_var', 'decoder.decoder_layers.0.1.num_batches_tracked', 'decoder.decoder_layers.1.0.weight', 'decoder.decoder_layers.1.0.bias', 'decoder.decoder_layers.1.1.weight', 'decoder.decoder_layers.1.1.bias', 'decoder.decoder_layers.1.1.running_mean', 'decoder.decoder_layers.1.1.running_var', 'decoder.decoder_layers.1.1.num_batches_tracked', 'decoder.decoder_layers.2.0.weight', 'decoder.decoder_layers.2.0.bias', 'decoder.decoder_layers.2.1.weight', 'decoder.decoder_layers.2.1.bias', 'decoder.decoder_layers.2.1.running_mean', 'decoder.decoder_layers.2.1.running_var', 'decoder.decoder_layers.2.1.num_batches_tracked', 'decoder.decoder_layers.3.0.weight', 'decoder.decoder_layers.3.0.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_path='hyperparameters.yaml'\n",
        "with open(config_path, 'r') as file:\n",
        "      config = yaml.safe_load(file)\n",
        "\n",
        "model2 = get_model(config).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAiR_y6G-0Gy",
        "outputId": "b7728176-4916-4d15-8a06-277fd0fd0617"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model_params': {'in_channels': 3, 'convbn_blocks': 4, 'conv_kernel_size': [3, 3, 3, 2], 'conv_kernel_strides': [2, 2, 1, 1], 'convbn_channels': [3, 6, 12, 24, 72], 'conv_activation_fn': 'relu', 'transpose_bn_blocks': 4, 'transposebn_channels': [72, 24, 12, 6, 3], 'transpose_kernel_size': [3, 3, 3, 2], 'transpose_kernel_strides': [2, 2, 1, 1], 'transpose_activation_fn': 'relu', 'latent_dim': 72, 'codebook_size': 10}, 'train_params': {'task_name': 'vqvae_latent_72_codebook_10_nnLayers_4', 'batch_size': 72, 'epochs': 10, 'lr': 0.005, 'crit': 'l2', 'reconstruction_loss_weight': 1, 'codebook_loss_weight': 1, 'commitment_loss_weight': 0.2, 'ckpt_name': 'best_vqvae_latent_72_codebook_10.pth', 'seed': 42, 'save_training_image': True, 'path': '/content/drive/MyDrive/Data/3dshapes.h5', 'output_train_dir': 'output'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.load_state_dict(state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HLgGUcM-yx8",
        "outputId": "82c2a47c-e4a2-4a36-a495-eb4325417012"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.quantizer.embedding.weight.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiSiWCl7_YtN",
        "outputId": "23fb62eb-d1f4-4277-e19f-2fa449c58503"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 72])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJiBesZnxh7C",
        "outputId": "6965d90b-afbe-40df-e0d1-b64b77c65ebb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 72])\n"
          ]
        }
      ],
      "source": [
        "# Load the tensor from the file\n",
        "loaded_tensor = torch.load('learned_codebook.pt')\n",
        "\n",
        "# Print the loaded tensor to verify\n",
        "print(loaded_tensor.shape)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}