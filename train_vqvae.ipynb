{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ZahraFayyaz/3dshape-vqvae-pyTorch/blob/main/3dshape_vqvae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uqt-IlG47el4"
   },
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from data_loader import load_data\n",
    "from vqvae import get_model\n",
    "# import argparse\n",
    "import random\n",
    "# import shutil\n",
    "import cv2\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "from torchvision.utils import make_grid\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22279,
     "status": "ok",
     "timestamp": 1721725526045,
     "user": {
      "displayName": "Mohsen Abgharian",
      "userId": "00588791625272270456"
     },
     "user_tz": -120
    },
    "id": "BjbJ19kth4El",
    "outputId": "3f2294c1-7372-4408-c0c1-efdc5f8a6fdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/My Drive/INI - Generative Episodic Memory\n"
     ]
    }
   ],
   "source": [
    "# connect to google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Enter the foldername where all modules are stored together\n",
    "FOLDERNAME = 'INI - Generative Episodic Memory/'\n",
    "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "# Change the working/current directory\n",
    "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
    "%cd /content/drive/My\\ Drive/$FOLDERNAME/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-mcnDTVS45Ih",
    "outputId": "21b8e327-6096-4bb6-808d-cd0c3f9a1cc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_params': {'in_channels': 3, 'convbn_blocks': 4, 'conv_kernel_size': [3, 3, 3, 2], 'conv_kernel_strides': [2, 2, 1, 1], 'convbn_channels': [3, 6, 12, 24, 72], 'conv_activation_fn': 'relu', 'transpose_bn_blocks': 4, 'transposebn_channels': [72, 24, 12, 6, 3], 'transpose_kernel_size': [3, 3, 3, 2], 'transpose_kernel_strides': [2, 2, 1, 1], 'transpose_activation_fn': 'relu', 'latent_dim': 72, 'codebook_size': 10}, 'train_params': {'task_name': 'vqvae_latent_72_codebook_10_nnLayers_4', 'batch_size': 72, 'epochs': 10, 'lr': 0.005, 'crit': 'l2', 'reconstruction_loss_weight': 1, 'codebook_loss_weight': 1, 'commitment_loss_weight': 0.2, 'ckpt_name': 'best_vqvae_latent_72_codebook_10.pth', 'seed': 42, 'save_training_image': True, 'path': '/home/mohsen/Desktop/Academia/RUB Research Projects/INI/data/3dshapes/3dshapes.h5', 'output_train_dir': 'output'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 1 | Recon Loss : 1.1372 | Codebook Loss : 1.2557 | Commitment Loss : 1.2557\n",
      "Improved Loss to 2.6440 .... Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 2 | Recon Loss : 0.9517 | Codebook Loss : 1.2116 | Commitment Loss : 1.2116\n",
      "Improved Loss to 2.4057 .... Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 3 | Recon Loss : 0.7589 | Codebook Loss : 1.1547 | Commitment Loss : 1.1547\n",
      "Improved Loss to 2.1445 .... Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 4 | Recon Loss : 0.6466 | Codebook Loss : 1.0892 | Commitment Loss : 1.0892\n",
      "Improved Loss to 1.9536 .... Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 5 | Recon Loss : 0.5572 | Codebook Loss : 1.0116 | Commitment Loss : 1.0116\n",
      "Improved Loss to 1.7712 .... Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 6 | Recon Loss : 0.4857 | Codebook Loss : 0.9330 | Commitment Loss : 0.9330\n",
      "Improved Loss to 1.6053 .... Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 7 | Recon Loss : 0.4282 | Codebook Loss : 0.8679 | Commitment Loss : 0.8679\n",
      "Improved Loss to 1.4697 .... Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 8 | Recon Loss : 0.3772 | Codebook Loss : 0.8166 | Commitment Loss : 0.8166\n",
      "Improved Loss to 1.3571 .... Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 9 | Recon Loss : 0.3292 | Codebook Loss : 0.7807 | Commitment Loss : 0.7807\n",
      "Improved Loss to 1.2660 .... Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 10 | Recon Loss : 0.2828 | Codebook Loss : 0.7524 | Commitment Loss : 0.7524\n",
      "Improved Loss to 1.1857 .... Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_for_one_epoch(epoch_idx, model, data_loader, optimizer, crtierion, config, save_indices=True):\n",
    "    r\"\"\"\n",
    "    Method to run the training for one epoch.\n",
    "    :param epoch_idx: iteration number of current epoch\n",
    "    :param model: VQVAE model\n",
    "    :param data_loader: Data loder for mnist\n",
    "    :param optimizer: optimzier to be used taken from config\n",
    "    :param crtierion: For computing the loss\n",
    "    :param config: configuration for the current run\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    recon_losses = []\n",
    "    codebook_losses = []\n",
    "    commitment_losses = []\n",
    "    losses = []\n",
    "    # List to collect indices of all images\n",
    "    all_indices = []\n",
    "\n",
    "    count = 0\n",
    "    for im, label in tqdm(data_loader, desc='Training', leave=False): # Ignore the label in DataLoader \n",
    "        im = im.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        model_output = model(im)\n",
    "        output = model_output['generated_image']\n",
    "        quantize_losses = model_output['quantized_losses']\n",
    "        z_q = model_output['quantized_output']\n",
    "        indices = model_output['quantized_indices']\n",
    "\n",
    "        # if config['train_params']['save_training_image']:\n",
    "        #     cv2.imwrite('input.jpeg', (255 * (im.detach() + 1) / 2).cpu().permute(0, 1, 2, 3).numpy().astype(np.uint8)) #(255 * (im.detach() + 1) / 2).cpu().permute((0, 2, 3, 1)).numpy()[0]\n",
    "        #     cv2.imwrite('output.jpeg', (255 * (output.detach() + 1) / 2).cpu().permute(0, 1, 2, 3).numpy().astype(np.uint8)) #(255 * (output.detach() + 1) / 2).cpu().permute((0, 2, 3, 1)).numpy()[0]\n",
    "\n",
    "        recon_loss = crtierion(output, im)\n",
    "        loss = (config['train_params']['reconstruction_loss_weight']*recon_loss +\n",
    "                config['train_params']['codebook_loss_weight']*quantize_losses['codebook_loss'] +\n",
    "                config['train_params']['commitment_loss_weight']*quantize_losses['commitment_loss'])\n",
    "        recon_losses.append(recon_loss.item())\n",
    "        codebook_losses.append(config['train_params']['codebook_loss_weight']*quantize_losses['codebook_loss'].item())\n",
    "        commitment_losses.append(quantize_losses['commitment_loss'].item())\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Collect indices for all images\n",
    "        all_indices.append(indices.cpu())\n",
    "\n",
    "    # Save indices if save_indices is True\n",
    "    if save_indices:\n",
    "        all_indices_tensor = torch.cat(all_indices, dim=0)\n",
    "\n",
    "    print('Finished epoch: {} | Recon Loss : {:.4f} | Codebook Loss : {:.4f} | Commitment Loss : {:.4f}'.\n",
    "          format(epoch_idx + 1,\n",
    "                 np.mean(recon_losses),\n",
    "                 np.mean(codebook_losses),\n",
    "                 np.mean(commitment_losses)))\n",
    "    return np.mean(losses), all_indices_tensor\n",
    "\n",
    "\n",
    "def train(config_path, sample=None):\n",
    "    ######## Read the config file #######\n",
    "    with open(config_path, 'r') as file:\n",
    "        try:\n",
    "            config = yaml.safe_load(file)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "    # print(config)\n",
    "    #######################################\n",
    "\n",
    "    ######## Set the desired seed value #######\n",
    "    seed = config['train_params']['seed']\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        # print(args.seed)\n",
    "    #######################################\n",
    "\n",
    "    # Create the model and dataset\n",
    "    model = get_model(config).to(device)\n",
    "    data_loader = load_data(config['train_params']['path'],sample_data=sample)\n",
    "    num_epochs = config['train_params']['epochs']\n",
    "    optimizer = Adam(model.parameters(), lr=config['train_params']['lr'])\n",
    "    # scheduler = ReduceLROnPlateau(optimizer, factor=0.5, patience=1, verbose=True)\n",
    "    criterion = {\n",
    "        'l1': torch.nn.L1Loss(),\n",
    "        'l2': torch.nn.MSELoss()\n",
    "    }.get(config['train_params']['crit'])\n",
    "\n",
    "    # Create output directories\n",
    "    if not os.path.exists(config['train_params']['task_name']):\n",
    "        os.mkdir(config['train_params']['task_name'])\n",
    "    if not os.path.exists(os.path.join(config['train_params']['task_name'],\n",
    "                                       config['train_params']['output_train_dir'])):\n",
    "        os.mkdir(os.path.join(config['train_params']['task_name'],\n",
    "                              config['train_params']['output_train_dir']))\n",
    "\n",
    "    # Load checkpoint if found\n",
    "    # if os.path.exists(os.path.join(config['train_params']['task_name'],\n",
    "        #                                                 config['train_params']['ckpt_name'])):\n",
    "        # print('Loading checkpoint')\n",
    "        # model.load_state_dict(torch.load(os.path.join(config['train_params']['task_name'],\n",
    "        #                                               config['train_params']['ckpt_name']), map_location=device))\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for epoch_idx in range(num_epochs):\n",
    "        mean_loss, indices_tensor = train_for_one_epoch(epoch_idx, model, data_loader, optimizer, criterion, config)\n",
    "        # scheduler.step(mean_loss)\n",
    "        # Simply update checkpoint if found better version\n",
    "        if mean_loss < best_loss:\n",
    "            print('Improved Loss to {:.4f} .... Saving Model'.format(mean_loss))\n",
    "            torch.save(model.state_dict(), os.path.join(config['train_params']['task_name'],\n",
    "                                                        config['train_params']['ckpt_name']))\n",
    "            best_loss = mean_loss\n",
    "        else:\n",
    "            print('No Loss Improvement')\n",
    "            \n",
    "    torch.save(indices_tensor, 'quantized_indices.pt')\n",
    "    embedding_weights = model.quantizer.embedding.weight.detach().cpu()\n",
    "    torch.save(embedding_weights, 'learned_codebook.pt')\n",
    "\n",
    "# def save_embedding_weights(model, file_path):\n",
    "#     # Save the learned embedding weights\n",
    "#     embedding_weights = model.quantizer.embedding.weight.detach().cpu()\n",
    "#     torch.save(embedding_weights, file_path)\n",
    "\n",
    "# def load_embedding_weights(file_path):\n",
    "#     # Load the saved embedding weights\n",
    "#     return torch.load(file_path)\n",
    "\n",
    "# def get_quantized_output_from_indices(model, indices):\n",
    "#     # Get quantized output from indices\n",
    "#     quantized_output = model.quantizer.quantize_indices(indices)\n",
    "#     return quantized_output\n",
    "\n",
    "\n",
    "train(config_path='hyperparameters.yaml')\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "# for fold, (train_idx, val_idx) in enumerate(kf.split(data)):\n",
    "#     print(f\"Fold {fold + 1}\")\n",
    "\n",
    "#     # Create data samplers\n",
    "#     train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "#     val_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
    "\n",
    "#     # Create data loaders\n",
    "#     train_loader = load_data(config['train_params']['path'],sample_data=train_sampler)\n",
    "#     val_loader = load_data(config['train_params']['path'],sample_data=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 72])\n"
     ]
    }
   ],
   "source": [
    "# Load the tensor from the file\n",
    "loaded_tensor = torch.load('learned_codebook.pt')\n",
    "\n",
    "# Print the loaded tensor to verify\n",
    "print(loaded_tensor.shape)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
